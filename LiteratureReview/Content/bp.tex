\section{Barren Plateaus, Gradients, Trainability Issue}
\todo{review QNN, VQA}

To solve a problem by using a Parameterized Quantum circuit, which can be an optimization task, calculating a chemical system, firstly, we encode the data into a Parameterized Circuit model: some input variables. 
Then design a cost function that represents the solution to the problem. We aim to minimize the cost function (the target solution to achieve) during the training process.

Initially, there are three ingredients some reference states (the inputs), a parameterized unitary operation (the circuit), and an observable $O$ to construct a cost function.
The next step is to use this parameterized circuit with some classical optimization algorithm on classical hardware.
Each run of the optimization routine receives the current value of the cost function and suggests the new set of parameters for the circuit \cite{cerezo2021variational}.
By changing the parameter, we are exploring an optimization landscape to find a global minimum.
The properties of this landscape heavily depend on the structure of the parameterized circuits and the cost function.

Typically, two starting ingredients for problem-solving using heuristic ansatzes are a random parameterized circuit $U$ and a set of random initialization parameters $\vec{\theta}$ \cite{mccleanBarrenPlateausQuantum2018}:
\begin{equation}\label{Parameterized Circuit}
    U(\vec{\theta})
    = U(\theta_1, \cdots, \theta_L)
    = \prod_{l=1}^L U_l(\theta_l)W_l
\end{equation}
Consider a cost function $C(\theta)$:
\begin{equation}\label{Cost function}
    C(\vec{\theta})
    = \bra{0} U(\vec{\theta})^\dagger OU(\vec{\theta}) \ket{0}
\end{equation}

The gradients are the derivatives of the cost function respectively to the parameters and have a severe impact on the performance of the training model:

\begin{equation}
    \partial_k C = \frac{\partial E(\vec{\theta})}{\partial\theta_k}
\end{equation}
McClean et al. in \cite{mccleanBarrenPlateausQuantum2018} also pointed out that whenever the random parameterized circuits are reaching the depth $O(n^{1/L})$ on a $L$-dimensional array, the gradient of the cost function will vanish \ref{Vanish Gradient}, and the variance of these gradients will be exponentially smaller with the number of qubit \ref{Variance expo smaller}. 

\begin{align}
    \langle \partial_k C\rangle &= 0  \label{Vanish Gradient}\\
    \mathrm{Var}[\partial_k C] &\approx 2^{-n}  \label{Variance expo smaller}
\end{align}

This phenomenon, known as "Barren Plateaus", is an issue for optimization because the flatter the landscape is, the more challenging it is to search for the location of the global minimum.

To summary, there are factors that lead to Barren Plateaus in QNN and VQA:
\begin{itemize}
    \item \textbf{Parameterized circuit depth;}
    \item \textbf{Random initialization parameters;}
\end{itemize}